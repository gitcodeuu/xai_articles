{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a1312fc59d017ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.007600Z",
     "start_time": "2025-11-01T13:33:02.997308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1 â€” Purpose & Overview\n",
    "#\n",
    "# This notebook exercises and validates the `process_article_file` function from `cleaner.py`\n",
    "# on a single example JSON. It is organized into small, numbered steps so you can run them\n",
    "# one-by-one or end-to-end.\n",
    "#\n",
    "# What this notebook is for\n",
    "# - Quickly test changes to `cleaner.py` on a single file before batch processing.\n",
    "# - Verify the transformation output structure and a short preview of the content.\n",
    "# - Troubleshoot common issues (missing imports, missing input file, or bad JSON).\n",
    "#\n",
    "# Inputs and outputs\n",
    "# - Input: a raw article JSON file located in the same folder as this notebook.\n",
    "# - Output: a transformed JSON written to the `./transformed_articles/` folder.\n",
    "#\n",
    "# What you will do\n",
    "# - Verify imports and environment (Step 2)\n",
    "# - Define input/output paths and filenames (Step 3)\n",
    "# - Validate the input and prepare the output folder (Step 4)\n",
    "# - Run the processing function (Step 5)\n",
    "# - Verify that the transformed file was produced and is valid JSON (Step 6)\n",
    "# - (Optional) Compare the original and transformed payloads (Step 7)\n",
    "# - (Optional) Reset the output file to re-run cleanly (Step 8)\n",
    "#\n",
    "# Tip: Run cells top-to-bottom the first time. Afterwards you typically only need\n",
    "# to tweak Step 3 and re-run Steps 4â€“6 while iterating on `cleaner.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989ce83395670c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.048096Z",
     "start_time": "2025-11-01T13:33:03.028791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imported 'process_article_file' from: d:\\CODE\\xai_articles\\xai_articles\\data_cleaner\\test_cleaner\\cleaner.py\n",
      "ðŸ•’ Run started: 2025-11-01 13:56:52\n",
      "ðŸ“ Working directory: d:\\CODE\\xai_articles\\xai_articles\\data_cleaner\\test_cleaner\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2 â€” Environment setup & imports\n",
    "# Sets up the Python environment and imports the processing function.\n",
    "# - Adds the parent directory to sys.path so `cleaner.py` can be imported.\n",
    "# - Prints a friendly message showing exactly which file was imported.\n",
    "# Troubleshooting:\n",
    "# - If the import fails, confirm `cleaner.py` is in the parent folder or adjust the path.\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# To import from the parent directory, we add it to the system path\n",
    "# This allows us to import the 'cleaner' module\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "try:\n",
    "    from cleaner import process_article_file  # type: ignore\n",
    "    cleaner_path = os.path.join(module_path, 'cleaner.py')\n",
    "    print(f\"âœ… Imported 'process_article_file' from: {cleaner_path}\")\n",
    "except Exception as e:\n",
    "    print(\"âŒ Failed to import from 'cleaner.py'.\\n\"\n",
    "          \"Make sure 'cleaner.py' exists in the parent folder.\")\n",
    "    raise\n",
    "\n",
    "print(f\"ðŸ•’ Run started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ðŸ“ Working directory: {Path.cwd()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68642bd1ff243d4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.070510Z",
     "start_time": "2025-11-01T13:33:03.064518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3 â€” Define input/output paths\n",
    "#\n",
    "# What this does\n",
    "# - Sets the base input directory to the current working directory (the notebook's folder).\n",
    "# - Points the output directory to `./transformed_articles/`.\n",
    "# - Lets you pick the input filename and the output filename explicitly.\n",
    "#\n",
    "# How to use\n",
    "# - Change `source_file_name` to any JSON sitting next to this notebook.\n",
    "# - By default `output_file_name` matches the input name; change it if you want a different name.\n",
    "# - We also remove any previous output file so the verification step reflects a fresh run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb58494330466a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.082633Z",
     "start_time": "2025-11-01T13:33:03.070510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸  Source file: d:\\CODE\\xai_articles\\xai_articles\\data_cleaner\\test_cleaner\\2025-01-31_1c6519de55247602e5d9757a4b5e5048.json\n",
      "â—€ï¸  Output file: d:\\CODE\\xai_articles\\xai_articles\\data_cleaner\\test_cleaner\\transformed_articles\\2025-01-31_1c6519de55247602e5d9757a4b5e5048.json\n",
      "ðŸ—‘ï¸ Removed previous output: d:\\CODE\\xai_articles\\xai_articles\\data_cleaner\\test_cleaner\\transformed_articles\\2025-01-31_1c6519de55247602e5d9757a4b5e5048.json\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "# Set the base directories. `Path.cwd()` should be this notebook's folder when run from VS Code/Jupyter.\n",
    "base_input_dir = Path.cwd()\n",
    "# All transformed files will be stored under this subfolder (created in Step 4 if missing).\n",
    "base_output_dir = base_input_dir / 'transformed_articles'\n",
    "\n",
    "# Quick Config â€” set the source and output file names\n",
    "# Pick the input file to process. Change to try a different article JSON.\n",
    "source_file_name = 'sample_article.json'  # change this to try another file\n",
    "# By default we write the output using the same filename; adjust if you want to keep multiple variants.\n",
    "output_file_name = source_file_name      # or set a different output name if desired\n",
    "\n",
    "# Resolve full paths used by the cleaner\n",
    "source_file_path = base_input_dir / source_file_name\n",
    "output_file_path = base_output_dir / output_file_name\n",
    "\n",
    "print(f\"â–¶ï¸  Source file: {source_file_path}\")\n",
    "print(f\"â—€ï¸  Output file: {output_file_path}\")\n",
    "\n",
    "# Remove any residue from previous runs for a clean slate\n",
    "# This ensures Step 5 writes a brand-new file (some cleaners skip overwriting existing outputs).\n",
    "if output_file_path.exists():\n",
    "    output_file_path.unlink()\n",
    "    print(f\"ðŸ—‘ï¸ Removed previous output: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6ba5b6787e4fa3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.098988Z",
     "start_time": "2025-11-01T13:33:03.094297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4 â€” Validate input and prepare output directory\n",
    "#\n",
    "# What this does\n",
    "# - Fails fast if the chosen input file does not exist (helps catch typos in the filename).\n",
    "# - Ensures the output directory exists (creates it if needed) so the next step can write the file.\n",
    "#\n",
    "# Why it matters\n",
    "# - Skipping these checks often leads to confusing errors later (e.g., JSON load errors or write failures).\n",
    "# - Creating the folder here keeps Step 5 focused purely on transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af440a60835558fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.111946Z",
     "start_time": "2025-11-01T13:33:03.098988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Output directory ready: d:\\CODE\\xai_articles\\xai_articles\\data_cleaner\\test_cleaner\\transformed_articles\n"
     ]
    }
   ],
   "source": [
    "# Ensure input exists\n",
    "if not source_file_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Input file not found: {source_file_path}. Place a JSON file next to this notebook.\"\n",
    "    )\n",
    "\n",
    "# Ensure output directory exists\n",
    "base_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"ðŸ“ Output directory ready: {base_output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0444566a3d2752c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.133864Z",
     "start_time": "2025-11-01T13:33:03.118874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5 â€” Run the processing function\n",
    "#\n",
    "# What this does\n",
    "# - Calls `process_article_file(source_file_path, base_input_dir, base_output_dir)` from `cleaner.py`.\n",
    "# - The function reads the input JSON, cleans and normalizes text (e.g., removes soft hyphens),\n",
    "#   enriches metadata (word count, reading time), and writes a new JSON into `./transformed_articles/`.\n",
    "#\n",
    "# Notes\n",
    "# - If an output file already exists, the cleaner may skip re-writing to avoid accidental overwrites.\n",
    "#   This notebook removes the previous output in Step 3 to ensure a fresh run.\n",
    "# - Any exceptions are printed by the cleaner; Step 6 will also fail if the output wasn't created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e54f64adad0c79a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.252055Z",
     "start_time": "2025-11-01T13:33:03.134884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ Running process_article_file(...) ...\n",
      "âœ… Transformed and saved: d:\\CODE\\xai_articles\\xai_articles\\data_cleaner\\test_cleaner\\transformed_articles\\2025-01-31_1c6519de55247602e5d9757a4b5e5048.json\n",
      "âœ… Processing finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run processing\n",
    "print(\"ðŸƒ Running process_article_file(...) ...\")\n",
    "# Call the cleaner with:\n",
    "# - source_file_path: the specific JSON file to transform\n",
    "# - base_input_dir:   the root path used to compute a relative output path\n",
    "# - base_output_dir:  the folder where transformed files are written\n",
    "process_article_file(source_file_path, base_input_dir, base_output_dir)\n",
    "print(\"âœ… Processing finished.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5da123ea235e53ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.283147Z",
     "start_time": "2025-11-01T13:33:03.275310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6 â€” Basic verification\n",
    "#\n",
    "# Purpose\n",
    "# - Confirm the transformed file was created in the expected location.\n",
    "# - Load both original and transformed JSON to ensure they are valid and comparable.\n",
    "# - Show a compact preview so you can spot-check key fields without dumping everything.\n",
    "#\n",
    "# What to look for\n",
    "# - The output file path printed in Step 3 should now exist.\n",
    "# - The transformed preview should include `article_id`, `source_info`, `metadata`, `content.article_body`, etc.\n",
    "# - If the loader fails here, the input may be malformed JSON or the cleaner may have raised an error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4a32408d7ee4637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.302313Z",
     "start_time": "2025-11-01T13:33:03.288212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Output JSON loaded successfully.\n",
      "â€¢ Original type:   dict\n",
      "â€¢ Transformed type:dict\n",
      "â€¢ Original keys (first 10):   ['title', 'author', 'content', 'tags', 'categories', 'image', 'retrievedAt', 'source', 'link', 'dateList']\n",
      "â€¢ Transformed keys (first 10):['article_id', 'source_info', 'metadata', 'content', 'entities']\n",
      "\n",
      "â€”â€” Transformed preview â€”â€”\n",
      "{\n",
      "  \"article_id\": \"2025-01-31_1c6519de55247602e5d9757a4b5e5048\",\n",
      "  \"source_info\": {\n",
      "    \"source_name\": \"Dawn\",\n",
      "    \"source_link\": \"https://www.dawn.com/news/1888755/nab-overseas-pakistanis-foundation-join-hands-to-protect-expats-from-fraud\",\n",
      "    \"retrieved_at\": \"2025-10-12T01:04:08.257Z\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"title\": \"NAB, Overseas Pakistanis Foundation join hands to protect expats from fraud - Business - DAWN.COM\",\n",
      "    \"author\": null,\n",
      "    \"date_published\": \"2025-01-31T02:25:27.000Z\",\n",
      "    \"image_url\": \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mN8Vw8AAmEBb87E6jIAAAAASUVORK5CYII=\",\n",
      "    \"categories\": [],\n",
      "    \"word_count\": 237,\n",
      "    \"reading_time_minutes\": 2\n",
      "  },\n",
      "  \"content\": {\n",
      "    \"article_body\": \"ISLAMABAD: The National Accountability Bureau (NAB) and the Overseas Pakistanis Foundation (OPF) on Thursday signed a memorandum of understanding to establish a framework for mutual cooperation and strategic coordination to address issues and complaints of overseas Pakistanis related to property disputes, financial fraud and misuse of authority. The main objective of the MoU was to create an efficient and collaborative mechanism whereby the OPF and NAB would jointly address and resolve grievances reported by overseas Pakistanis. According to a press release, such grievances may encompass, without limitation, fraudulent practices in housing schemes, disputes pertaining to property possession, allotment and incidents of financial mismanagement or irregularities perpetrated by housing developers and private individuals. Under MoU, a dedicated facilitation desk or cell at all NAB offices, including the head office, will be established to receive and process complaints referred by the OPF or overseas Pakistanis, directly. A helpline will be established between NAB and the OPF for constant liaison to address complaints. Earlier, an OPF delegation gave a detailed briefing on the working of the OPF and issues faced by oversees Pakistanis. On the occasion, the NAB chairman emphasised that overseas Pakistanis are a valuable asset of the country, and the bureau, in collaboration with the OPF, will take all possible measures to resolve their issues. He said NAB would ensure that those who cheated overseas Pakistanis would be given appropriate legal punishments. Published in Dawn, January 31st, 2025\",\n",
      "    \"summary\": \"\",\n",
      "    \"keywords\": []\n",
      "  },\n",
      "  \"entities\": {\n",
      "    \"people\": [],\n",
      "    \"organizations\": [],\n",
      "    \"locations\": []\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Verify output file\n",
    "if not output_file_path.exists():\n",
    "    raise RuntimeError(\n",
    "        f\"Expected output was not created: {output_file_path}. Check errors above.\"\n",
    "    )\n",
    "\n",
    "# Load original and transformed\n",
    "with open(source_file_path, 'r', encoding='utf-8') as f:\n",
    "    original_data = json.load(f)\n",
    "with open(output_file_path, 'r', encoding='utf-8') as f:\n",
    "    transformed_data = json.load(f)\n",
    "\n",
    "# Quick sanity info\n",
    "orig_keys = list(original_data.keys()) if isinstance(original_data, dict) else None\n",
    "trans_keys = list(transformed_data.keys()) if isinstance(transformed_data, dict) else None\n",
    "\n",
    "print(\"âœ… Output JSON loaded successfully.\")\n",
    "print(f\"â€¢ Original type:   {type(original_data).__name__}\")\n",
    "print(f\"â€¢ Transformed type:{type(transformed_data).__name__}\")\n",
    "if orig_keys is not None:\n",
    "    print(f\"â€¢ Original keys (first 10):   {orig_keys[:10]}\")\n",
    "if trans_keys is not None:\n",
    "    print(f\"â€¢ Transformed keys (first 10):{trans_keys[:10]}\")\n",
    "\n",
    "# Preview transformed snippet\n",
    "# For convenience, build a compact preview without dumping the whole file:\n",
    "# - If the transformed object is a list/tuple, show only the first element.\n",
    "# - If it's a dict, show up to the first 10 top-level keys.\n",
    "preview = transformed_data\n",
    "if isinstance(transformed_data, (list, tuple)) and len(transformed_data) > 0:\n",
    "    preview = transformed_data[0]\n",
    "elif isinstance(transformed_data, dict):\n",
    "    preview = {k: transformed_data[k] for i, k in enumerate(transformed_data) if i < 10}\n",
    "\n",
    "print(\"\\nâ€”â€” Transformed preview â€”â€”\")\n",
    "print(json.dumps(preview, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "855e3438e3234318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.326964Z",
     "start_time": "2025-11-01T13:33:03.321341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 7 â€” (Optional) Compare full original vs transformed\n",
    "#\n",
    "# What this does\n",
    "# - Prints the complete original JSON and the complete transformed JSON for side-by-side inspection.\n",
    "# - Useful when debugging field mappings or missing values that don't show up in the preview.\n",
    "#\n",
    "# Caution\n",
    "# - For very large inputs, printing the entire payload can be slow and clutter the output.\n",
    "# - Leave `show_full = False` for routine checks; enable only when you need the full context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8acb3148cb9d9983",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.338933Z",
     "start_time": "2025-11-01T13:33:03.332982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Skipped full dump â€” set 'show_full = True' to print everything.)\n"
     ]
    }
   ],
   "source": [
    "show_full = False  # set to True to print full payloads\n",
    "if show_full:\n",
    "    print(\"================ ORIGINAL DATA ================\")\n",
    "    print(json.dumps(original_data, indent=2, ensure_ascii=False))\n",
    "    print(\"\\n\\n============== TRANSFORMED DATA ==============\")\n",
    "    print(json.dumps(transformed_data, indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(\"(Skipped full dump â€” set 'show_full = True' to print everything.)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae44f751b6fabee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.354873Z",
     "start_time": "2025-11-01T13:33:03.348403Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 8 â€” (Optional) Reset output\n",
    "#\n",
    "# What this does\n",
    "# - Deletes the generated transformed file so you can re-run Steps 5â€“6 and see fresh output.\n",
    "# - Useful when testing changes to `cleaner.py` that would otherwise be skipped if a file already exists.\n",
    "#\n",
    "# How to use\n",
    "# - Set `reset_output = True` to remove the file printed in Step 3.\n",
    "# - Leave it `False` to keep the artifact for later inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ef5b89682181433",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.375350Z",
     "start_time": "2025-11-01T13:33:03.367467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Output kept â€” set 'reset_output = True' to remove it.)\n"
     ]
    }
   ],
   "source": [
    "reset_output = False  # set to True to remove the generated file\n",
    "if reset_output and output_file_path.exists():\n",
    "    output_file_path.unlink()\n",
    "    print(f\"ðŸ§¹ Removed: {output_file_path}\")\n",
    "else:\n",
    "    print(\"(Output kept â€” set 'reset_output = True' to remove it.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8dd0acbc2e0233",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T13:33:03.397623Z",
     "start_time": "2025-11-01T13:33:03.394160Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
