{
  "title": "MEDIA: THE AI STORM DROWNING PAKISTAN",
  "author": "Seerat Khan",
  "content": "The climate crisis in Pakistan over the years has exacerbated to the extent that it has become the new norm, with floods impacting cities, livelihoods and homes of millions of people in the country. In 2025 alone, Pakistan experienced devastating floods, with an estimated 4.2 million people affected in Punjab, according to the United Nations Office for the Coordination of Humanitarian Affairs (UNOCHA).\n\nAs the floodwaters rose, however, a parallel crisis emerged online. In response to the floods,  many Pakistanis turned to digital technologies for weather updates, relief efforts and communicating with communities affected by the floods.\n\nAt the same time, in response to this reliance on updates from digital platforms, there’s also been a rapid surge in climate change disinformation, intended to sensationalise an already tragic environment and garner more views for spreading confusion.\n\nMore alarmingly, the surge of generative artificial intelligence (AI) on platforms has largely gone unchecked. This has allowed manufactured information to be widely believed, promoting dangerous narratives online.\n\nMillions of Pakistanis affected by floods are turning to social media for help. Instead, they’re finding AI-generated lies: fake geopolitical attacks, sexualised “rescue” videos and fabricated tragedies designed to maximise engagement\n\nTHE RISE OF MISINFORMATION\n\nA recent study by the Lahore-based Digital Rights Foundation (DRF) of which I was a co-author, Combatting Flood Misinformation in Pakistan: Generative AI and Platform Accountability in the Age of Climate Crisis, investigated some of these trends and the kind of misinformation being fuelled on platforms, leading to further polarisation and dangerous narratives being promoted.\n\nThe report points out how AI is being weaponised in the climate crisis, with viral TikTok visuals portraying India’s release of dam water into overflowing rivers downstream into Pakistani Punjab as a deliberate act of hostility. This AI-generated footage on various social media platforms has been dramatising this narrative, depicting Indian workers maliciously releasing water as a calculated tactic of war.\n\nThis framing of a natural catastrophe within a singular geopolitical narrative, fuels existing India-Pakistan tensions. More critically, it serves to divert attention from domestic shortcomings in governance, flood management and relief efforts.\n\nSuch narratives are often pushed by bad-faith actors, seeking to profit from engagement or to advance divisive political agendas, exploiting the climate crisis for their own ends.\n\nToday, when 40 per cent of Pakistan’s population remains illiterate and generative AI is becoming more advanced and sophisticated, it is becoming increasingly difficult to identify information online as being disinformation or authentic news, with many falling into the trap of climate disinformation online. The combination of low digital literacy, the inherent realism of AI-generated content and a high-stakes crisis creates a perfect storm for misinformation to thrive.\n\nBeyond geopolitical narratives, AI-generated content has also enabled a more insidious form of exploitation: technology-facilitated gender-based violence, including the rise of AI-generated “woman-in-crisis” content. The trend has been seen across multiple platforms, where AI-generated depictions of women are used both to elicit sympathy and to exploit a natural disaster as a vehicle for sexualising women’s bodies.\n\nTikTok and Instagram are rife with such videos, showing rural women navigating flooded landscapes, often carrying babies. These clips attract thousands of views, yet only a small fraction carry TikTok’s “AI content” label.\n\nFollowing this theme, users have been seen posting hyper-sexualised depictions of women in flood settings, shifting the focus from the floods to women’s bodies. This sets a dangerous precedent in a context where women already face heightened risks of gender-based violence during disasters in relief camps.\n\nPakistani TikTok and Instagram accounts have also been producing “AI village fetish” content, including videos portraying unconscious women being touched inappropriately under the guise of “rescue”, and bad actors have exploited the floods as another opportunity for engagement.\n\nThe DRF report uncovered several AI-generated videos depicting women drenched in floodwaters with men groping them under the pretext of saving them.\n\nThis sexualisation also appears in village-vlog-style videos, where an AI-generated woman ostensibly documents the destruction of her flooded village. Yet the focus of these clips remains on her physical appearance and body rather than the devastation itself. While less explicit, these videos still perpetuate objectification to maximise engagement.\n\nAlarmingly, comments on such content show that many older Pakistani users interpret these videos as genuine depictions of women affected by floods, which shows the urgent need for clear and prominent AI labelling.\n\nWithout such safeguards, misinformation not only distorts reality but also normalises the exploitation of women’s bodies during humanitarian crises.\n\nEXPLOITING TRAGEDIES\n\nSimilarly, AI has also been used to exploit real tragedies, such as an Instagram reel recreating the tragedy that unfolded in Swat in June this year. At least 17 people were caught for hours in the middle of the river after the water suddenly surged, before being swept away and drowning.\n\nThe entirely AI-generated clip fabricates visuals and overlays screaming voices of the victims. This type of synthetic content is deeply insensitive and dangerous. It has the ability to distort the memory of a real disaster, trivialise the suffering of survivors and spread misinformation among audiences already grappling with fear and grief.\n\nThis fictionalisation of human tragedy for clicks and engagement not only undermines trust but also risks retraumatising affected communities.\n\nPLATFORM ACCOUNTABILITY\n\nAt this time, while social media platforms are flooded with climate-related misinformation, TikTok remains the only platform to provide cautionary warnings and links to flood-related information for Pakistani users.\n\nAlthough its flood safety guide marked a positive step, the initiative has been limited in scope. TikTok, like many other social media platforms, has failed to adequately address the scale of misinformation, particularly from generative AI content. These platforms do not cater to regional languages or reflect Pakistan’s diverse media landscape. As a result, outreach has always been restricted to a relatively small segment of users who can read and comprehend English and Urdu.\n\nIn moments of crisis, social media platforms carry a responsibility to uphold global standards. The UN Guiding Principles on Business and Human Rights (UNGPs) provide a clear benchmark to companies to respect users’ rights and mitigate harm, which includes curbing disaster-related misinformation, as part of their duty to protect human rights in digital spaces.\n\nMisinformation during emergencies is not a trivial issue. It can compromise humanitarian aid and disaster response by changing perceptions, damaging credibility, and disrupting coordination.\n\nAs climate catastrophes become a recurring norm, striking Pakistan almost every year, platforms have a responsibility to support users during crises, rather than adding to these challenges in an already impending disaster.\n\nThe writer is Research and Grants Lead at the Digital Rights Foundation, Lahore. She can be contacted via Info@digitalrightsfoundation.pk\n\nPublished in Dawn, EOS, October 19th, 2025\n\nNewsKit Publishing Platform",
  "tags": [],
  "categories": [
    "News"
  ],
  "image": "https://i.dawn.com/large/2025/10/68f2f45bb7700.jpg",
  "retrievedAt": "2025-10-23T20:17:32.890Z",
  "source": "DAWN",
  "link": "https://www.dawn.com/news/1949538",
  "dateList": "2025-10-23",
  "date_published": "2025-10-19T03:14:08.000Z"
}
