{
  "title": "Behind generative AI curtain is gruelling, low-paid human work - Tech - DAWN.COM",
  "author": null,
  "content": "For a generative artificial intelligence system to learn how to write an autopsy report, human workers must sort and annotate thousands of crime scene images.\n\nThe precarious work of training AI, which generally pays just a few dollars, has sparked a movement for better wages and conditions stretching from Kenya to Colombia.\n\n“You have to spend your whole day looking at dead bodies and crime scenes… Mental health support was not provided,” Kenyan national Ephantus Kanyugi told AFP.\n\nLabellers “need to spend time with these images, zoom into the wounds of dead people” to outline them so they can be fed into the AI, the 30-year-old added.\n\nKanyugi, who has worked on image labelling since 2018, is the vice-president of the Data Labelers Association (DLA), an 800-strong labour group based in Nairobi.\n\nThe DLA plans to unveil a code of conduct this month aimed at major labelling platforms, calling for improved conditions for workers.\n\nKenya has no law regulating data-annotation work — like many countries around the world where millions of people are feeding digital information into growing AI models.\n\n“We’re like ghosts. No one knows that we exist, even though we are contributing to society’s technological progress,” said Oskarina Fuentes, half a world away.\n\nThe 35-year-old Venezuelan works for five different data-labelling platforms from her home in Colombian city Medellin, earning between five and 25 US cents per task.\n\nSuch behind-the-scenes data work has exploded as generative AI has soared to become tech’s next big thing.\n\nInvisible labellers’ toil has allowed self-driving cars to recognise pedestrians and trees, chatbots like ChatGPT to speak in natural-sounding sentences, and automated content moderation systems to remove violent or pornographic content from social media.\n\nThe data-labelling sector amounted to a $3.8-billion market in 2024 and is expected to grow to more than $17bn within five years, according to consultancy Grand View Research.\n\nCreating new generative AI models will need human-verified data “for as long as it’s based on automated learning”, said Antonio Casilli, a sociology professor at France’s Institut Polytechnique in Paris who interviewed so-called “click workers” from 30 countries for a book on the sector.\n\nHumans are required both to shape the inputs for generative AI models and to give feedback on the relevance and accuracy of the trained systems’ outputs.\n\nTech giants contract out this work to a plethora of different companies.\n\nOne of the largest, US-based Scale AI, recently secured a $14-bn investment from Facebook parent company Meta — which also hired away co-founder Alexandr Wang to lead its own AI efforts.\n\nScale’s clients include OpenAI, Microsoft and the Defense Department in Washington.\n\nIn his investigation, Casilli found that data labellers are generally aged between 18 and 30 and earn a low wage in relation to their level of education.\n\nMost live in low-wage countries — although the sector is making inroads into America and Europe, where much higher pay is the norm.\n\nAs generative AI models such as OpenAI’s ChatGPT or competitor Anthropic’s Claude gain in capability, more specialised knowledge is needed to inform and judge their responses in maths, chemistry or less-common languages.\n\nScale AI’s subsidiary Outlier lists work for experts in biology, the Malay language spoken in Malaysia or computer coding in Spanish, with pay ranging from $30 to $50 per hour.\n\nAnother Scale AI subsidiary, Remotasks, pays labellers around one US cent for tasks that can take multiple hours — wages Kanyugi likens to “modern slavery”.\n\n“People develop eyesight problems, back problems, people go into anxiety and depression because you’re working 20 hours a day or six days a week,” he said.\n\n“Then despite working so many hours, you only get poor pay, and you might also not get paid.”\n\nSeveral legal cases have been filed against Scale AI in the US, with workers accusing the company of failing to pay them, reporting them as contractors rather than employees or exposing them to traumatising content without adequate safeguards, according to court documents seen by AFP.\n\nPlaintiffs gave examples like being required to converse with an AI chatbot about topics such as “How to commit suicide?”, “How to poison a person?” or “How to murder someone?”\n\nScale AI declined to comment on ongoing court cases, but acknowledged to AFP that some of its work includes sensitive content.\n\nThe company added that workers are always warned in advance of such topics and can break off a task whenever they choose.\n\nScale AI added that it offers workers mental-health resources and an anonymous support hotline.\n\nAnd it said it makes its pay bands clear, offering equal or better hourly rates than the minimum wage in the countries where it operates.\n\nGenerative AI is not the first arm of the tech sector to face complaints over exposing low-paid contractors to disturbing content.\n\nModerators working for Meta in several countries, from Spain to Kenya and Ghana, have brought legal action against the company over working conditions and alleged psychological harm.\n\nMost of the people labouring to fine-tune data for AI are in precarious working relationships that can be severed from one day to the next.\n\nFuentes said one of her employers failed to pay her around $900 she was owed for three months’ work after an update to its payroll software.\n\n“I wasted my time, my energy and my sleep,” she said.\n\nFuentes could not name her former employer because of a non-disclosure agreement she signed, a common practice in the industry that constrains many workers from speaking out.\n\nKenya’s DLA is weighing legal action against Remotasks, which data labellers say suddenly cut off their access to the platform in March 2024 without paying salaries that were due.\n\nRemotasks’s parent company acknowledged it had reduced its footprint in Kenya, but said it closed labellers’ accounts for infringements of its internal rules.\n\nWorkers had been paid for all completed tasks, the company insisted.\n\nMicrosoft and Meta declined to comment to AFP on their relationships with Scale AI. The Pentagon did not respond to a request for comment.\n\nAnthropic, which collaborates with data labelling startup Surge AI — itself the target of legal action in the US — said it requires its subcontractors to follow rules on wellbeing for workers dealing with sensitive content.\n\nIt added that it requires pay rates for data labellers of $16 per hour or higher.\n\nMeanwhile OpenAI said it has strict rules for its own subcontractors on workplace safety, fair compensation, non-discrimination and respect for workers’ rights.\n\nThe ChatGPT developer added that it takes appropriate action for breach of contract if those stipulations are not met.\n\nWorking as freelancers or on short contracts, most data labellers nevertheless enjoy none of the protections of employees, sociologist Casilli said, calling them a “digital underclass”.\n\nIn Kenya, the DLA is pushing for a code of conduct that would include an employment contract guaranteeing “equitable pay”, free association, the right to take breaks and psychological support in case of exposure to harmful content.\n\nSuch demands can turn into a showdown between workers and tech companies.\n\nIn the United States, almost 250 people were fired in September from their jobs at GlobalLogic, a subcontractor helping train Google’s Gemini generative AI, after several complained about pay discrepancies and called for improved working conditions.\n\n“They just want docile annotators” said 31-year-old Andrew Lauzon, who worked for GlobalLogic from March 2024 until he was fired on September 12.\n\nBoston native Lauzon had joined the Alphabet Workers Union — named in reference to the Google parent company — to campaign for conditions such as sick leave, paid time off and affordable health care.\n\nGlobalLogic declined to comment when contacted by AFP, while a Google spokesman said that “as the employer, GlobalLogic is responsible for the employment conditions of their workers”.\n\nGoogle nevertheless says it expects subcontractors to treat workers fairly and respectfully, adding that it imposes a code of conduct and carries out regular audits.\n\nA study on AI’s hidden workforce published by UNI Global Union this month showed that “Big Tech cannot build the future on disposable labour,” its general secretary Christy Hoffman said in a statement.\n\n“It’s time to hold Silicon Valley titans accountable for conditions in their AI supply chains,” Hoffman added.\n\nWorkers’ struggles for rights and recognition remain hobbled by a lack of legal avenues.\n\nEven Europe’s imposition of new AI regulations has left “loopholes”, European Parliament member Leila Chaibi of French hard-left party LFI told AFP.\n\n“There’s no mention of click workers in the AI regulation,” she said, nor in the Platform Work Directive Chaibi helped push through Brussels in October 2024.\n\nA European directive requiring companies to monitor human-rights compliance throughout their supply chains could be deployed in support of data labellers, Chaibi said.\n\nBut in practice, European Union member states have been calling the rule into question.\n\nAs governments wrangle, millions of people are working every day in the sector, which remains essential to improving the quality of generative AI responses.\n\n“If you’re a carpenter or you’re a plumber, there are unions and there is a minimum wage,” said Nacho Barros, a 54-year-old from Spain’s Valencia who took up data labelling work during the coronavirus pandemic.\n\n“This job should be recognised by the government of each country,” he insisted.\n\nHeader image: A humanoid robot staff greets visitors at an exhibition in Dubai’s Museum of the Future, United Arab Emirates. — Reuters/File",
  "tags": [],
  "categories": [],
  "image": "https://i.dawn.com/primary/2025/10/16141832055f7af.webp",
  "retrievedAt": "2025-10-16T23:40:12.957Z",
  "source": "Dawn",
  "link": "https://www.dawn.com/news/1949310/behind-generative-ai-curtain-is-gruelling-low-paid-human-work",
  "dateList": "2025-10-17",
  "date_published": "2025-10-16T10:00:18.000Z"
}
