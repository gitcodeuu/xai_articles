{
  "title": "The age of AI - Newspaper - DAWN.COM",
  "author": null,
  "content": "STAR Trek is an iconic sci-fi series from the 1980s. Set in the 24th century, it showcases astounding technological leaps. One unmissable character is a humanoid robot called Data. Although immensely capable, he’s unable to experience emotions; any attempt returns comical failures.\n\nMeanwhile, humans have spread to other planets. In one episode, one such planet is visited by a powerful character Ardra. A contract is said to entitle her to ownership of both the planet and its inhabitants. The people submit to her, convinced of her power and authenticity; however, the protagonist, Captain Picard, demands arbitration. Confident of success, Ardra agrees but only if Data is the arbiter. Her reason: the artificial intelligence (AI) within him “is incapable of deceit and bias”. Hold that thought!\n\nWe may not yet have a Data, but we are unmistakably in the age of AI. It can conduct surgeries, decide lawsuits and drive cars. But imagine having your chest ripped open by a robot which, although well-calibrated and immune to fatigue, overestimates your pain threshold because of your skin colour. Now switch to a courtroom, where an AI judge — invited by the honourable Supreme Court — hands down a life sentence without explaining the decision, as the commercial licence prohibits disclosure. The scene shifts again: you are in a self-driving car, thoroughly tested in the US but unable to recognise a donkey cart in Pakistan, and it accelerates instead of stopping.\n\nThese are no improbable hypotheticals. AI learns from human experiences fed to it during training; any exceptions result in biased decisions that can be inconvenient, life-changing, even fatal. For example, in 2016, a passport application of an Asian man in New Zealand was rejected because AI declared the eyes in his photo were closed. They weren’t. They were only smaller. The applicant had ‘no hard feelings’ against the robot. Glenn Rodríguez, though, wanted to be released from jail after an exemplary 26-year record. However, the proprietary AI system COMPAS denied his parole application; and the board had no idea why. Later research showed that COMPAS deemed him high-risk simply because he was black. In 2016 again, a self-driving Tesla crashed into a truck because it mistook its white side for the sky. The driver died.\n\nThe point is not to scare anyone, it is to raise awareness. AI holds immense potential, but its ability to mimic or even surpass human accuracy across a range of situations can inflate trust in its safety and ethicality, ignoring the fact that the learning process behind this impressive performance is not faithful to human cognition and neurobiology. Also, modern AI systems are complex, with properties that may only be discovered long after their creation. They can embed systemic human bias and perpetuate it at scale: due to limited medical access, dermatological data grossly underrepresents people with darker skin tones. This leaves even doctors with little evidence to test the efficacy of costly treatments — and AI risks reinforcing such under-treatment. Accordingly, legislation such as the EU AI Act classifies systems impacting human welfare, opportunities and safety as high-risk to stamp the importance of the responsible use of AI.\n\nAI’s ability to mimic human accuracy can inflate trust in its safety.\n\nFor an ethnically, environmentally and socioeconomically diverse Pakistan, this presents challenges and opportunities. Bias is multidimensional and cannot be estimated or even defined without engaging stakeholders in a cross-spectrum manner. Therefore, this is an opportunity for researchers from both the technical and social sciences to collectively engage communities and develop contextually aware and demographically representative AI systems for Pakistan. By embracing this appr­o­ach, Pakistan can st­­r­ategically cultivate AI solutions that are in­­herently fairer and more effective for its unique sub-populatio­­ns, directly addressing existing healthcare inequalities and ensuring equitable outcomes in areas like criminal justice and economic opportunities.\n\nTo enable broader societal uptake and understanding, it is also important to develop conversion courses that allow people from all academic backgrounds to engage with AI. Experience from the UK shows that such courses attract students from diverse fields and foster stakeholder engagement directly within the classroom.\n\nFairness, equity and justice are divine ideals, yet they are fundamental to human dignity. The quest for them has now turned to machines. But will artificial intelligence succeed where biological intelligence has failed? This question brings empirical ethics into the spotlight. Regardless, the road to the elusive ideal of true justice is paved with the fundamentals of transparency, integrity and inclusivity.\n\nThe writer is professor of artificial intelligence at Birmingham City University.\n\nPublished in Dawn, August 18th, 2025",
  "tags": [],
  "categories": [],
  "image": "https://i.dawn.com/primary/2025/08/68a2898838277.jpg",
  "retrievedAt": "2025-10-12T03:51:45.237Z",
  "source": "Dawn",
  "link": "https://www.dawn.com/news/1931620/the-age-of-ai",
  "dateList": "2025-08-19",
  "date_published": "2025-08-18T02:05:39.000Z"
}
