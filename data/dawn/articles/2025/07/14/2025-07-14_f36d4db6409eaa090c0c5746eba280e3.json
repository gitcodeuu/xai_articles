{
  "title": "Hold your AI horses - Pakistan - DAWN.COM",
  "author": null,
  "content": "“HOW important is it that any company using AI for its work has a dedicated department overseeing its usage?” I asked ChatGPT and here’s what it said: “It’s increasingly important — but not always essential — for companies using AI to have some form of dedicated and structured oversight.”\n\nThe above is a summary of a detailed answer, which, credit to the bot, also took into account the different ways unmanned use of AI could be harmful. Unfortunately, the majority of the people, companies and institutions keen on incorporating generative AI into their lives and work are not paying heed to this advice itself and omitting the “always” from “not always essential”.\n\nGenerative AI is no longer a new terminology or technology, and neither is its use. The ease of access to AI programmes is also not new; in fact, users don’t even have to go looking for it anymore as even a mundane Google search now thrusts an ‘AI Overview’ upon you right at the beginning — a feature that cannot be turned off.\n\nWhat is new, and will remain so with the continuous development of the technology, is how its application is evolving and in majority cases, alarmingly so without taking stock of its legal and ethical implications, or its risks and limitations. It is only fair to think that AI and its capabilities can aid in efficient governance, medical research and practices, academic endeavours, business and technology — across all industries, really. But the notion of AI tools ‘saving’ time or money cannot be the driving force behind using them; the premise has to be whether they are actually improving productivity, quality and/or delivering intended results.\n\nPakistan is enthusiastic as to what AI can do, but the country has yet to formalise its National AI Policy.\n\nPakistan, like the rest of the world, is enthusiastic as to what AI can do, but the country has yet to formalise its National AI Policy which was drafted in May 2023 by the Ministry of IT & Telecom. More than two years later, the draft is still that: a draft. In the same time period, AI technology has witnessed leaps and bounds in its functions and adoption.\n\nWhen the draft was shared, multiple groups, including the Digital Rights Foundation, had given feedback to improve its clauses. Debates over its contents — and the word in Islamabad is that there haven’t been many — have been kept out of public discourse. To think that government departments are not using AI tools in some way to assist with their work in the meantime is far-fetched, which begs the question as to what liberties might be being taken without any regard for the downsides, data privacy to name one.\n\nMany countries have taken steps towards integrating AI consciously; the United Arab Emirates appointed an AI minister — the first ever — back in 2017. Kenya, in March this year, launched its National Artificial Intelligence Strategy (2025-2030), saying: “This is a commitment to shaping Kenya’s digital future. Kenya will not be a spectator; we will be architects of our digital destiny.” This is not to say that these are the metrics one needs to achieve for the ideal use of AI — these are the starting points.\n\nWithin industries, some in Pakistan have taken the initiative to use AI with policies in place. The Aga Khan University, for example, alongside a number of guidelines on the matter, has a dedicated AI Division to assist residents, fellows, research staff and faculty members.\n\nA positive ruling also came from the judiciary in April, when a two-member Supreme Court bench acknowledged AI’s advantages, saying that it should support, not supplant, human judgement. The ruling mandated that the National Judicial Committee, in partnership with the Law and Justice Commission of Pakistan, establish clear guidelines for AI’s ethical and constitutional use. While progress has yet to be made in this regard, tying the use to a policy is still a very encouraging step. The State Bank of Pakistan is also actively working on finalising the guidelines for the responsible use of AI in financial services.\n\nThe media industry, however, is lagging even further behind our national AI policy. Most newsrooms don’t even have a draft of a policy or official guidelines but have okayed the use of AI tools. While alarm bells for verifying information or content via generative AI have been rung loud and clear, other risks such as biases — internalised by AI systems from their training data — and hallucinations are largely, if not completely, being ignored. Recently, a prominent media group’s Instagram page had a post on a story to do with black magic in Pakistan, and the AI image featured five women, warts and all, wearing black capes and pointed hats. Such a cliché and gender-biased visual representation of the story shouldn’t need a dedicated person to call it out but at least, if in place, such an authority could have caught it or set some guidelines for future use of the tool and prompt in question.\n\nCompanies are also missing the point that such departments will allow room for growth — innovation beyond AI’s obvious and open-to-all uses. At the speed with which generative AI tools are being incorporated, from organisations to individuals, it will only become harder to produce content that can stand apart. Comedian John Oliver’s noteworthy segment on “AI Slop” put it aptly: “Spread of AI generation tools has made it very easy to mass produce and flood social media sites with cheap, professional-looking, often deeply weird content.”\n\nAI evolution is a reality that must be adopted, but questioning how that’s being done doesn’t make you a detractor. Also, using the argument that automated AI tools have always been a part of people’s lives and work operations is a weak and ignorant one, taking away from the fact that we’re now dealing with a much more sophisticated ‘live’ version of the technology that is continuously progressing. It’s only logical then that the same gusto with which we’re embracing a racing technology is shown for periodically updated policies and dedicated departments. After all, AI is not the problem, relying on it without guardrails is.\n\nThe writer is Dawn.com’s Deputy Editor and project lead for a fact-check initiative.\n\nPublished in Dawn, July 14th, 2025",
  "tags": [],
  "categories": [],
  "image": "https://i.dawn.com/primary/2025/07/687469cd9d63c.jpg",
  "retrievedAt": "2025-08-17T20:25:42.861Z",
  "source": "Dawn",
  "link": "https://www.dawn.com/news/1924070/hold-your-ai-horses",
  "dateList": "2025-07-14",
  "date_published": "2025-07-14T02:22:15.000Z"
}
