{
  "title": "Nations meet at UN for ‘killer robot’ talks as regulation lags - World - DAWN.COM",
  "author": null,
  "content": "GENEVA: Countries are meeting at the United Nations on Monday to revive efforts to regulate the kinds of AI-controlled autonomous weapons increasingly used in modern warfare, as experts warn time is running out to put guardrails on new lethal technology.\n\nAutonomous and artificial intelligence-assisted weapons systems are already playing a greater role in conflicts from Ukraine to Gaza. And rising defence spending worldwide promises to provide a further boost for burgeoning AI-assisted military technology.\n\nProgress towards establishing global rules governing their development and use, however, has not kept pace. And internationally binding standards remain virtually non-existent.\n\nSince 2014, countries that are part of the Convention on Conventional Weapons (CCW) have been meeting in Geneva to discuss a potential ban fully autonomous systems that operate without meaningful human control and regulate others.\n\nAutonomous and AI-assisted weapons systems are playing a bigger role in conflicts\n\nUN Secretary-General Antonio Guterres has set a 2026 deadline for states to establish clear rules on AI weapon use. But human rights groups warn that consensus among governments is lacking.\n\nAlexander Kmentt, head of arms control at Austria’s foreign ministry, said that must quickly change.\n\n“Time is really running out to put in some guardrails so that the nightmare scenarios that some of the most noted experts are warning of don’t come to pass,” he said.\n\nMonday’s gathering of the UN General Assembly in New York will be the body’s first meeting de­­dicated to autonomous weapons.\n\nThough not legally binding, diplomatic officials want the consultations to ramp up pressure on military powers that are resisting regulation due to concerns the rules could dull the technology’s battlefield advantages.\n\nCampaign groups hope the meeting, which will also address critical issues not covered by the CCW, including ethical and human rights concerns and the use of autonomous weapons by non-state actors, will push states to agree on a legal instrument.\n\nThey view it as a crucial litmus test on whether countries are able to bridge divisions ahead of the next round of CCW talks in September.\n\n“This issue needs clarification through a legally binding treaty. The technology is moving so fast,” said Patrick Wilcken, Amnesty International’s Researcher on Military, Security and Policing.\n\n“The idea that you wouldn’t want to rule out the delegation of life or death decisions … to a machine seems extraordinary.”\n\nArms race\n\nThe New York talks come after 164 states supported a 2023 UN General Assembly resolution calling for the international community to urgently address the risks posed by autonomous weapons.\n\nWhile many countries back a binding global framework, the United States, Russia, China and India prefer national guidelines or existing international laws, according to Amnesty.\n\n“We have not been convinced that existing law is insufficient,” a US Pentagon spokesperson said, adding that autonomous weapons might actually pose less risk to ci­­v­­­ilians than conventional weapons.\n\nThe governments of India, Russia, and China did not respond to requests for comment.\n\nIn the absence of regulation, autonomous systems are proliferating.\n\nWeapons experts at the Future of Life Institute think tank have tracked the deployment of roughly 200 autonomous weapon systems across Ukraine, the Middle East and Africa.\n\nRussian forces, for example, have deployed some 3,000 Veter kamikaze drones — capable of autonomously detecting and engaging targets — to Ukraine, according to its data.\n\nUkraine has, meanwhile, used semi-autonomous drones in the conflict. The Ukrainian government declined to comment.\n\nIsrael has used AI-systems to identify targets in Gaza. Its mission in Geneva said it supported multilateral discussions and uses data technologies in full accordance with international law.\n\nHuman Rights Watch, however, said crucial questions of accountability under international law remain unresolved and warned in a report last month that unregulated autonomous weapons present a range of threats to human rights and could provoke an arms race if unchecked.\n\nAnd campaigners like Laura Nolan of Stop Killer Robots worry there is currently little to ensure defence firms will develop AI-driven weapons responsibly.\n\n“We do not generally trust industries to self-regulate … There is no reason why defence or technology companies should be more worthy of trust,” she said.\n\nPublished in Dawn, May 13th, 2025",
  "tags": [],
  "categories": [],
  "image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mN8Vw8AAmEBb87E6jIAAAAASUVORK5CYII=",
  "retrievedAt": "2025-10-12T03:02:01.672Z",
  "source": "Dawn",
  "link": "https://www.dawn.com/news/1910617/nations-meet-at-un-for-killer-robot-talks-as-regulation-lags",
  "dateList": "2025-05-13",
  "date_published": "2025-05-13T01:33:09.000Z"
}
